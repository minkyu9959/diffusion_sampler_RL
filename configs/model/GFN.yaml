_target_: sampler.gfn.models.GFN

defaults:
  - components@state_encoder: StateEncoding

  - components@time_encoder: TimeEncoding

  - components@forward_policy: JointPolicy

  - components@backward_policy: JointPolicy

  - components@flow_model: FlowModel

  - components@langevin_scaler: LangevinScaling

  - prior_energy: Gaussian # hey prior energy modified

forward_policy:
  s_dim: ${energy.dim}
  s_emb_dim: ${model.state_encoder.s_emb_dim}
  t_dim: ${model.time_encoder.t_emb_dim}
  hidden_dim: 256
  num_layers: 2

backward_policy:
  s_dim: ${energy.dim}
  s_emb_dim: ${model.state_encoder.s_emb_dim}
  t_dim: ${model.time_encoder.t_emb_dim}
  hidden_dim: ${model.forward_policy.hidden_dim}
  num_layers: ${model.forward_policy.num_layers}

state_encoder:
  s_dim: ${energy.dim}
  s_emb_dim: 128

time_encoder:
  t_emb_dim: 128
  harmonics_dim: ${.t_emb_dim}

# If yout want to scale gradient of energy dimension-wise,
# you can set out_dim to ${energy.dim}.
langevin_scaler:
  s_emb_dim: ${model.state_encoder.s_emb_dim}
  t_dim: ${model.time_encoder.t_emb_dim}
  hidden_dim: ${model.forward_policy.hidden_dim}
  out_dim: ${energy.dim}

trajectory_length: 100

t_scale: 1.0
learned_variance: false
log_var_range: 4.0

pb_scale_range: 0.1

clipping: true
lgv_clip: 1e2
gfn_clip: 1e4

fixed_logZ: false

optimizer_cfg:
  lr_policy: 1e-3
  lr_flow: 1e-1
  lr_back: 1e-3
  weight_decay: 1e-7
  use_weight_decay: false
  max_grad_norm: null